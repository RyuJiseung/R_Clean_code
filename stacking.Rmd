
---
title: 'Modeling - KKBox EDA'
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---

## Load libraries and helper functions
```{r, message = FALSE}
# general visualisation
library(needs)
needs(dplyr,ggplot2,reshape2,scales,grid,gridExtra,RColorBrewer,corrplot,
      readr,MLmetrics,randomForest,gbm,h2o,
        data.table,tibble,tidyr,stringr,forcats,lubridate,ggridges,caret,Matrix,
      xgboost,caret,dplyr)
```



## Load data
```{r warning=FALSE, results=FALSE}
train_df <- read_csv('~/Desktop/r스터디(목)/6_kaggle_competition/data/train_df_train_real.csv')
test_df <- read_csv('~/Desktop/r스터디(목)/6_kaggle_competition/data/test_df.csv')
train_df<-train_df[,1:23]
test_df<-test_df[,1:23]
train_df$is_churn <- as.factor(train_df$is_churn) 
test_df$is_churn <- as.factor(test_df$is_churn)
```


## 셋 구분
```{r}
seed <- 1
set.seed(seed)
idx <- sample(1:nrow(train_df), size = nrow(train_df)*0.7)
# 훈련 데이터
train <- as.data.frame(train_df[idx,])
train$is_churn<-as.factor(train$is_churn)
# 테스트 데이터
val <- as.data.frame(train_df[!1:nrow(train_df) %in% idx,])
val$is_churn<-as.factor(val$is_churn)
```


## H2O 클러스터
```{r}
h2o.init(nthreads = -1, max_mem_size = '8G')
train_df$is_churn<-as.factor(train_df$is_churn)
train_Hex<-as.h2o(train_df)

val$is_churn<-as.factor(val$is_churn)
val_Hex<-as.h2o(val)

test_df$is_churn <- c(rep(1,(nrow(test_df)+1)/2),rep(0,(nrow(test_df)-1)/2))
test_df$is_churn <- as.factor(test_df$is_churn)
test_Hex<-as.h2o(test_df)
```

## Modeling
```{r}
predictors <- setdiff(names(train_df),
                       c("is_churn", "msno"))
response <- "is_churn"
```

## gbm
```{r}
gbm <- h2o.gbm(x = predictors,
                      y = response,
                      training_frame = train_Hex,
                      validation_frame = val_Hex,
                      ntree=200,
                      seed=950902)

pred_gbm <- h2o.predict(gbm,test_Hex)

test_df$gbm <- as.vector(pred_gbm$p1)

temp <- test_df %>% select(msno,gbm)
colnames(temp) <- c("msno","is_churn")
write.csv(temp,"gbm.csv",row.names=FALSE)

gbm@model$variable_importances
```

## xgboost
```{r}
xgboost <- h2o.xgboost(x = predictors,
                      y = response,
                      training_frame = train_Hex,
                      validation_frame = val_Hex,
                      ntree=200,
                      seed=950902)

pred_xgboost <- h2o.predict(xgboost,test_Hex)


test_df$xgboost <- as.vector(pred_xgboost$C3)

temp <- test_df %>% select(msno,xgboost)
colnames(temp) <- c("msno","is_churn")
write.csv(temp,"xgboost.csv",row.names=FALSE)


xgboost@model$variable_importances

sum(test_df$msno %in% train_df$msno)
table(train_df$is_churn)
```

## rf
```{r}
rf <- h2o.randomForest(x = predictors,
                      y = response,
                      training_frame = train_Hex,
                      validation_frame = val_Hex,
                      ntree=200,
                      seed=950902)


pred_rf <- h2o.predict(rf,test_Hex)

test_df$rf <- as.vector(pred_rf$p1)

temp <- test_df %>% select(msno,rf)
colnames(temp) <- c("msno","is_churn")
write.csv(temp,"rf.csv",row.names=FALSE)

rf@model$variable_importances
```

## glm
```{r}
glm_x <- h2o.glm(x = predictors
                  ,y = response
                 ,nfolds=3
                  ,training_frame = train_Hex,
                      validation_frame = val_Hex,
                 family = "binomial",
                 alpha=0.01,
                 lambda=1.0E-8,
                      seed=950902,
                      link = "logit")

pred_glm_x <- h2o.predict(glm_x,test_Hex)

test_df$glm <- as.vector(pred_glm_x$p1)

temp <- test_df %>% select(msno,glm)
colnames(temp) <- c("msno","is_churn")
write.csv(temp,"glm.csv",row.names=FALSE)

```

## deeplearning
```{r}
deeplearning <-  h2o.deeplearning(
    training_frame = train_Hex,
    validation_frame = val_Hex,
    seed = 950902,# validation dataset: used for scoring and early stopping
   x = predictors,
    y = response,
    activation = "Rectifier", # default (a.k.a Relu)
    hidden = c(200, 200),    # default = 2 hidden layers with 200 neurons each
    epochs = 1,
   l1=1.0E-4,
   input_dropout_ratio= 0.05,
# How many times the dataset should be iterated
    variable_importances = TRUE,
    stopping_metric = "misclassification",
    stopping_tolerance = 1e-2, # stop when logloss does not improve by >=1% for 2 scoring events
    stopping_rounds = 2,
    score_validation_samples = 10000# allows obtaining the variable importance, not enabled by default
)

pred_deeplearning <- h2o.predict(deeplearning,test_Hex)

test_df$deeplearning <- as.vector(pred_deeplearning$p1)

temp <- test_df %>% select(msno,deeplearning)
colnames(temp) <- c("msno","is_churn")
write.csv(temp,"deeplearning.csv",row.names=FALSE)




deeplearning@model$variable_importances
```



# best deeplearning
```{r}
# # train samples of the training data for speed
# sampled_train <- train_Hex
#
# # specify the list of paramters
# hyper_params <- list(
#     hidden = list( c(100,100), c(150,150), c(200,200)),
#     input_dropout_ratio = c(0, 0.05),
#     l1 = c(1e-4, 1e-3)
# )
#
# # performs the grid search
# grid_id <- "dl_grid"
# model_dl_grid <- h2o.grid(
#     algorithm = "deeplearning", # name of the algorithm
#     grid_id = grid_id,
#     training_frame = sampled_train,
#     validation_frame = val_Hex,
#     seed = 950902,# validation dataset: used for scoring and early stopping
#    x = predictors,
#     y = response,
#     epochs = 1,
#     stopping_metric = "misclassification",
#     stopping_tolerance = 1e-2, # stop when logloss does not improve by >=1% for 2 scoring events
#     stopping_rounds = 2,
#     score_validation_samples = 10000, # downsample validation set for faster scoring
#     hyper_params = hyper_params
# )
#
# # find the best model and evaluate its performance
# stopping_metric <- 'accuracy'
# sorted_models <- h2o.getGrid(
#     grid_id = grid_id,
#     sort_by = stopping_metric,
#     decreasing = TRUE
# )
#
# best_model <- h2o.getModel(sorted_models@model_ids[[2]])
# pred3 <- h2o.predict(best_model, test_Hex)
#
#
# test_df$deeplearning_tun_1 <- as.vector(pred3$p1)
#
# temp <- test_df %>% select(msno,deeplearning_tun_1)
# colnames(temp) <- c("msno","is_churn")
# write.csv(temp,"deeplearning_grid_2.csv",row.names=FALSE)
#
#
# best_model <- h2o.getModel(sorted_models@model_ids[[3]])
# pred3 <- h2o.predict(best_model, test_Hex)
#
#
# test_df$deeplearning_tun_1 <- as.vector(pred3$p1)
#
# temp <- test_df %>% select(msno,deeplearning_tun_1)
# colnames(temp) <- c("msno","is_churn")
# write.csv(temp,"deeplearning_grid_1.csv",row.names=FALSE)
```



```{r}
# GLM Hyperparamters
# alpha_opt <- c(0.01,0.1,0.3,0.5,0.7,0.9)
# lambda_opt <- c(1e-4,1e-5,1e-6,1e-7,1e-8)
# hyper_params_glm <- list(alpha = alpha_opt,
#                      lambda = lambda_opt)
#
# search_criteria_glm <- list(
#   strategy = "RandomDiscrete",
#                         max_models = 100,
#                         seed = 950902)
#
# grid_glm <- h2o.grid(algorithm = "glm",
#                      x = predictors,
#                     y = response,
#                     family="binomial",
#                     training_frame = train_Hex,
#                     validation_frame = val_Hex,
#                      seed = 950902,
#                      hyper_params = hyper_params_glm,
#                      search_criteria = search_criteria_glm)
# summary(grid_glm)

```



```{r}
# # randomForest Hyperparamters
# # learn_rate_opt <- c(0.01, 0.03)
# max_depth_opt <- c(3, 4, 5, 6, 9)
# sample_rate_opt <- c(0.7, 0.8, 0.9, 1.0)
# col_sample_rate_opt <- c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)
# hyper_params_randomForest <- list(
#   # learn_rate = learn_rate_opt,
#                      max_depth = max_depth_opt,
#                      sample_rate = sample_rate_opt,
#                      col_sample_rate = col_sample_rate_opt)
#
# search_criteria_randomForest <- list(strategy = "RandomDiscrete",
#                         max_models = 20,
#                         seed = 950902)
#
# gbm_grid_randomForest <- h2o.grid(algorithm = "randomForest",
#                      grid_id = "rf_grid_binomial",
#                      x = predictors,
#                     y = response,
#                     training_frame = train_Hex,
#                       validation_frame = val_Hex,
#                      ntrees = 200,
#                      seed = 950902,
#                      hyper_params = hyper_params_randomForest,
#                      search_criteria = search_criteria_randomForest)

```



```{r}

nfolds=3

# 1. Generate a 2-model ensemble (GBM + RF)

# Train & Cross-validate a GBM
my_gbm <- h2o.gbm(   x = predictors,
                      y = response,
                  training_frame = train_Hex, 
                  distribution = "bernoulli",
                  ntrees = 200,
                  # max_depth = 3,
                  # min_rows = 2,
                  # learn_rate = 0.2,
                  nfolds = nfolds,
                  fold_assignment = "Modulo",
                  keep_cross_validation_predictions = TRUE,
                  seed = 1)

# Train & Cross-validate a XGboost
my_xgb <- h2o.xgboost(   x = predictors,
                      y = response,
                  training_frame = train_Hex, 
                  ntrees = 200,
                  # max_depth = 3,
                  # min_rows = 2,
                  # learn_rate = 0.2,
                  nfolds = nfolds,
                  fold_assignment = "Modulo",
                  keep_cross_validation_predictions = TRUE,
                  seed = 1)

# Train & Cross-validate a RF
my_rf <- h2o.randomForest(   x = predictors,
                      y = response,
                  training_frame = train_Hex, 
                          ntrees = 200,
                          nfolds = nfolds,
                          fold_assignment = "Modulo",
                          keep_cross_validation_predictions = TRUE,
                          seed = 1)

# Train a stacked ensemble using the GBM and RF above
ensemble <- h2o.stackedEnsemble(   x = predictors,
                      y = response,
                  training_frame = train_Hex, 
                                model_id = "my_ensemble_binomial",
                                base_models = list(my_gbm, my_rf,my_xgb))


# Eval ensemble performance on a test_Hex set
perf <- h2o.performance(ensemble, newdata = test_Hex)

# Compare to base learner performance on the test_Hex set
perf_gbm_test_Hex <- h2o.performance(my_gbm, newdata = test_Hex)
perf_rf_test_Hex <- h2o.performance(my_rf, newdata = test_Hex)
baselearner_best_auc_test_Hex <- max(h2o.auc(perf_gbm_test_Hex), h2o.auc(perf_rf_test_Hex))
ensemble_auc_test_Hex <- h2o.auc(perf)
print(sprintf("Best Base-learner test_Hex AUC:  %s", baselearner_best_auc_test_Hex))
print(sprintf("Ensemble test_Hex AUC:  %s", ensemble_auc_test_Hex))

# Generate predictions on a test_Hex set (if neccessary)
pred <- h2o.predict(ensemble, newdata = test_Hex)

tet_df$is_churn <- pred$p1
temp <- temp %>% select(msno, is_churn)
write.csv(temp,"ensemble.csv",row.names=FALSE)
```

```{r}
# 
# 2. Generate a random grid of models and stack them together

# GBM Hyperparamters
learn_rate_opt <- c(0.01, 0.03)
max_depth_opt <- c(3, 4, 5, 6, 9)
sample_rate_opt <- c(0.7, 0.8, 0.9, 1.0)
col_sample_rate_opt <- c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)
hyper_params <- list(learn_rate = learn_rate_opt,
                     max_depth = max_depth_opt,
                     sample_rate = sample_rate_opt,
                     col_sample_rate = col_sample_rate_opt)

search_criteria <- list(strategy = "RandomDiscrete",
                        max_models = 3,
                        seed = 1)

gbm_grid <- h2o.grid(algorithm = "gbm",
                     grid_id = "gbm_grid_binomial",
                     x = x,
                     y = y,
                     training_frame = train_Hex,
                     ntrees = 10,
                     seed = 1,
                     nfolds = nfolds,
                     fold_assignment = "Modulo",
                     keep_cross_validation_predictions = TRUE,
                     hyper_params = hyper_params,
                     search_criteria = search_criteria)

# # Train a stacked ensemble using the GBM grid
# ensemble <- h2o.stackedEnsemble(x = x,
#                                 y = y,
#                                 training_frame = train_Hex,
#                                 model_id = "ensemble_gbm_grid_binomial",
#                                 base_models = gbm_grid@model_ids)
# 
# # Eval ensemble performance on a test_Hex set
# perf <- h2o.performance(ensemble, newdata = test_Hex)
# 
# # Compare to base learner performance on the test_Hex set
# .getauc <- function(mm) h2o.auc(h2o.performance(h2o.getModel(mm), newdata = test_Hex))
# baselearner_aucs <- sapply(gbm_grid@model_ids, .getauc)
# baselearner_best_auc_test_Hex <- max(baselearner_aucs)
# ensemble_auc_test_Hex <- h2o.auc(perf)
# print(sprintf("Best Base-learner test_Hex AUC:  %s", baselearner_best_auc_test_Hex))
# print(sprintf("Ensemble test_Hex AUC:  %s", ensemble_auc_test_Hex))
# 
# # Generate predictions on a test_Hex set (if neccessary)
# pred <- h2o.predict(ensemble, newdata = test_Hex)
```


```{r}
#============================
# Define the wrapper function
#============================
h2o_bayes <- function(
  max_depth, learn_rate, sample_rate, 
  col_sample_rate, balance_classes){
  bal.cl <- as.logical(balance_classes)
  gbm <- h2o.gbm(  
                      x = predictors,
                      y = response,
                  training_frame = train_Hex, 
    validation_frame    = val_Hex,
    #nfolds              = 3,
    ntrees              = 900,
    max_depth           = max_depth,
    learn_rate          = learn_rate,
    sample_rate         = sample_rate,
    col_sample_rate     = col_sample_rate,
    score_tree_interval = 5,
    stopping_rounds     = 2,
    stopping_metric     = "logloss",
    stopping_tolerance  = 0.005,
    balance_classes     = bal.cl)
    
  score <- h2o.auc(gbm, valid = T)
  list(Score = score,
       Pred  = 0)
}

#============================
# Find optimal values for the 
# parameters in the given range. 
#============================
OPT_Res <- BayesianOptimization(
  h2o_bayes,
  bounds = list(
    max_depth   = c(2L, 8L), 
    learn_rate  = c(1e-4, 0.2),
    sample_rate = c(0.4, 1), 
    col_sample_rate = c(0.4, 1), 
    balance_classes = c(0L, 1L)),
  init_points = 10,  n_iter = 10,
  acq = "ucb", kappa = 2.576, eps = 0.0,
  verbose = FALSE)
```
<!-- http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/stacked-ensembles.html -->

<!-- https://a-ghorbani.github.io/2016/11/24/data-science-with-h2o#bayesian-optimization -->

```{r}
gbm <- h2o.gbm(
                      x = predictors,
                      y = response,
                  training_frame = train_Hex, 
    validation_frame    = val_Hex,
  ntrees              = 900,
  max_depth           = OPT_Res$Best_Par["max_depth"],
  learn_rate          = OPT_Res$Best_Par["learn_rate"],
  sample_rate         = OPT_Res$Best_Par["sample_rate"],
  col_sample_rate     = OPT_Res$Best_Par["col_sample_rate"],
  balance_classes     = as.logical(OPT_Res$Best_Par["balance_classes"]),
  score_tree_interval = 5,
  stopping_rounds     = 2,
  stopping_metric     = "logloss",
  stopping_tolerance  = 0.005,
  model_id         = "my_awesome_GBM")
```
```{r}
var.imp <- h2o.varimp(gbm)[h2o.varimp(gbm)$scaled_importance > 0.05, "variable"]
# The value of 0.05 is arbitrary, you might want to use other values.
# 제거된 것
setdiff(predictors, var.imp)
```

```{r}
gbm_varImp <- h2o.gbm(
  x                   = var.imp,
                      y = response,
                  training_frame = train_Hex, 
    validation_frame    = val_Hex,
  ntrees              = 900,
  max_depth           = OPT_Res$Best_Par["max_depth"],
  learn_rate          = OPT_Res$Best_Par["learn_rate"],
  sample_rate         = OPT_Res$Best_Par["sample_rate"],
  col_sample_rate     = OPT_Res$Best_Par["col_sample_rate"],
  balance_classes     = as.logical(OPT_Res$Best_Par["balance_classes"]),
  score_tree_interval = 5,
  stopping_rounds     = 2,
  stopping_metric     = "logloss",
  stopping_tolerance  = 0.005,
  model_id         = "my_awesome_GBM_varImp")
```

```{r}
shist <- gbm@model$scoring_history[, c("duration", "validation_rmse", "validation_auc")]
shist$algorithm <- "GBM" 
scoring_history <- shist

shist <- gbm_varImp@model$scoring_history[, c("duration", "validation_rmse", "validation_auc")]
shist$algorithm <- "GBM with var.imp." 
scoring_history <- rbind(scoring_history,shist)

# scoring_history$duration <- ifelse(nchar(scoring_history$duration)>13,substr(scoring_history$duration,1,2)

scoring_history$duration <- ifelse(nchar(gsub("min", "", gsub("sec", "", scoring_history$duration)))<9,
                                   as.numeric(gsub("min", "", gsub("sec", "", scoring_history$duration))),
                                    as.numeric(substr(gsub("min", "", gsub("sec", "", scoring_history$duration)),1,2))*60+
                                    as.numeric(substr(gsub("min", "", gsub("sec", "", scoring_history$duration)),4,10)))

scoring_history <- melt(scoring_history, id = c("duration", "algorithm"))

ggplot(data = scoring_history, 
       aes(x     = duration, 
           y     = value, 
           color = algorithm,
           group = algorithm)) + 
  geom_line() + geom_point() +
  facet_grid(. ~ variable, scales = "free",shrink = TRUE,space = "free")
```

```{r}
AUC_gbm        <- h2o.performance(gbm, valid = T)@metrics$AUC
AUC_gbm_varImp <- h2o.performance(gbm_varImp, valid = T)@metrics$AUC
if(AUC_gbm > AUC_gbm_varImp){
  bestModel <- gbm
}else{
  bestModel <- gbm_varImp
}
cat("The best model is '", bestModel@model_id, 
    "' with AUC of ", max(AUC_gbm, AUC_gbm_varImp), 
    " vs ",  min(AUC_gbm, AUC_gbm_varImp), "\n" )
```

```{r}
bestPerf <- h2o.performance(bestModel, test_Hex)

perfDF <- melt(as.data.frame(bestPerf@metrics$thresholds_and_metric_scores), 
           id = "threshold")
```

```{r}
as.data.frame(
    bestPerf@metrics[c("MSE", "RMSE", "AUC", "r2", "logloss", "Gini", "mean_per_class_error")]
    )
```

```{r}
kable(bestPerf@metrics$max_criteria_and_metric_scores, digits = 3)
```

```{r}
scores_to_plot <- c("accuracy", "precision", "recall", "min_per_class_accuracy")

ggplot(data = perfDF[perfDF$variable %in% scores_to_plot, ],  
       aes(x     = threshold, 
           y     = value, 
           color = variable,
           group = variable)) + 
  geom_line() + geom_point() 
```
```{r}
h2o.varimp_plot(bestModel)
```



